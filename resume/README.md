# STAN Internship Challenge - Human-like Conversational Chatbot

ðŸ¤– **LIVE DEMO**: [Chat with the AI](https://your-chatbot-url.netlify.app) | ðŸ“š **API Docs**: [Backend API](https://your-backend-url.railway.app/docs)

A sophisticated full-stack chatbot application with human-like conversation capabilities, memory persistence, and context awareness. This project demonstrates advanced NLP techniques and efficient memory management for creating more natural AI interactions.

## ðŸŽ¯ Challenge Requirements âœ…

All STAN Internship Challenge requirements have been successfully implemented:

- âœ… **Human-like Conversations**: Natural, emotional, and engaging interactions
- âœ… **Memory & Personalization**: Persistent user profiles across sessions  
- âœ… **Non-Google AI Models**: OpenAI GPT and Anthropic Claude integration
- âœ… **Efficient Storage**: ChromaDB vector store with PostgreSQL/SQLite
- âœ… **Modular Backend**: Pluggable FastAPI architecture
- âœ… **Clean Documentation**: Comprehensive guides and API docs
- âœ… **All 7 Test Cases**: Memory recall, tone adaptation, personalization validated

## ðŸš€ **LIVE DEPLOYMENT**

The chatbot is production-ready and can be deployed to live web hosting with one command:

### Quick Deploy (Windows)
```bash
cd chatbot-project
deploy.bat
```

### Quick Deploy (Linux/Mac)
```bash
cd chatbot-project
chmod +x deploy.sh
./deploy.sh
```

### Manual Deployment Options
- **Railway** (Backend) + **Netlify** (Frontend) - Recommended
- **Heroku** (Backend) + **Vercel** (Frontend) - Alternative
- **Docker** deployment to any cloud provider

## Features

- **Human-like Interaction**: Natural, emotional, and engaging conversations with personality consistency
- **Memory & Personalization**: Per-user profiles and preferences stored efficiently
- **Context Awareness**: Maintains conversation flow and recalls previous topics
- **Adaptive Tone**: Shifts between formal/informal based on context
- **Emotional Intelligence**: Callbacks to previous emotional moments in conversations
- **Multi-model Support**: Integration with OpenAI GPT, Claude, and Mistral models
- **Efficient Storage**: Optimized memory persistence with multi-tiered approach
- **Cost Optimization**: Token compression and efficient context management

## Project Structure

```
â”œâ”€â”€ backend/               # Python FastAPI backend
â”‚   â”œâ”€â”€ app/              # Application code
â”‚   â”‚   â”œâ”€â”€ api/          # API endpoints
â”‚   â”‚   â”œâ”€â”€ core/         # Core functionality
â”‚   â”‚   â”œâ”€â”€ db/           # Database models and connections
â”‚   â”‚   â”œâ”€â”€ memory/       # Memory system implementation
â”‚   â”‚   â”œâ”€â”€ models/       # Data models
â”‚   â”‚   â”œâ”€â”€ services/     # Business logic services
â”‚   â”‚   â””â”€â”€ utils/        # Utility functions
â”‚   â”œâ”€â”€ tests/            # Backend tests
â”‚   â”œâ”€â”€ .env.example      # Environment variables example
â”‚   â”œâ”€â”€ requirements.txt  # Python dependencies
â”‚   â””â”€â”€ main.py           # Application entry point
â”œâ”€â”€ frontend/             # React frontend
â”‚   â”œâ”€â”€ public/           # Public assets
â”‚   â”œâ”€â”€ src/              # Source code
â”‚   â”‚   â”œâ”€â”€ components/   # React components
â”‚   â”‚   â”œâ”€â”€ contexts/     # React contexts
â”‚   â”‚   â”œâ”€â”€ hooks/        # Custom hooks
â”‚   â”‚   â”œâ”€â”€ pages/        # Application pages
â”‚   â”‚   â”œâ”€â”€ services/     # API services
â”‚   â”‚   â”œâ”€â”€ styles/       # CSS styles
â”‚   â”‚   â”œâ”€â”€ utils/        # Utility functions
â”‚   â”‚   â”œâ”€â”€ App.jsx       # Main application component
â”‚   â”‚   â””â”€â”€ index.jsx     # Entry point
â”‚   â”œâ”€â”€ package.json      # NPM dependencies
â”‚   â””â”€â”€ vite.config.js    # Vite configuration
â”œâ”€â”€ docs/                 # Documentation
â”‚   â””â”€â”€ architecture.pdf  # Architecture document
â”œâ”€â”€ docker-compose.yml    # Docker Compose configuration
â”œâ”€â”€ .gitignore            # Git ignore file
â””â”€â”€ README.md             # Project documentation
```

## Technology Stack

### Backend
- Python 3.9+
- FastAPI (web framework)
- SQLAlchemy (ORM)
- PostgreSQL (relational database)
- Redis (caching and session management)
- Pinecone/Qdrant (vector database for embeddings)
- OpenAI API / Anthropic Claude API / Mistral API

### Frontend
- React 18+
- Vite (build tool)
- TailwindCSS (styling)
- Axios (HTTP client)

## Setup Instructions

### Prerequisites
- Python 3.9+
- Node.js 16+
- PostgreSQL
- Redis
- Docker & Docker Compose (optional)

### Backend Setup

1. Navigate to the backend directory:
   ```bash
   cd backend
   ```

2. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Create a `.env` file based on `.env.example` and configure your environment variables.

5. Run the application:
   ```bash
   uvicorn app.main:app --reload
   ```

### Frontend Setup

1. Navigate to the frontend directory:
   ```bash
   cd frontend
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Create a `.env` file based on `.env.example` and configure your environment variables.

4. Run the development server:
   ```bash
   npm run dev
   ```

### Docker Setup (Optional)

1. Build and start the containers:
   ```bash
   docker-compose up -d
   ```

## API Documentation

Once the backend is running, you can access the API documentation at:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## Memory System Architecture

The chatbot's memory system consists of three components:

1. **Short-term Memory**: Recent conversation turns stored in Redis for fast access
   - Caches user preferences and active conversation state
   - Provides immediate context for the current conversation

2. **Long-term Memory**: Complete conversation history in PostgreSQL
   - Stores all messages with metadata (sentiment, tokens, timestamps)
   - Enables recalling specific conversations across sessions

3. **Semantic Memory**: Vector embeddings for semantic search in Qdrant/Pinecone
   - Converts messages to embeddings for similarity search
   - Allows retrieving contextually relevant information based on semantic meaning
   - Supports "remembering" topics discussed in previous conversations

This multi-tiered approach enables the chatbot to:
- Maintain conversation flow within a session
- Recall previous interactions across sessions
- Retrieve relevant information based on semantic similarity
- Adapt responses based on user preferences and conversation history

## Testing

### Backend Tests

```bash
cd backend
python -m pytest
```

### Frontend Tests

```bash
cd frontend
npm test
```

## License

MIT